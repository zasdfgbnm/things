{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5.0a0+0c91d4c\n",
      "0c91d4c8af90fef4b333b37f965b9e0515e37569\n",
      "\n",
      "Running:\n",
      "rm -rf BinaryArithmeticKernel.sm_70.cubin; cuobjdump -xelf BinaryArithmeticKernel.sm_70.cubin /home/xgao/anaconda3/lib/python3.7/site-packages/torch/lib/libtorch_cuda.so\n",
      "\n",
      "**Symbol:**\n",
      "void at::native::elementwise_kernel<512, 1, at::native::gpu_kernel_impl<at::native::add_kernel_cuda(at::TensorIterator&, c10::Scalar)::{lambda()#1}::operator()() const::{lambda()#4}::operator()() const::{lambda(float, float)#1}>(at::TensorIterator&, at::native::add_kernel_cuda(at::TensorIterator&, c10::Scalar)::{lambda()#1}::operator()() const::{lambda()#4}::operator()() const::{lambda(float, float)#1} const&)::{lambda(int)#2}>(int, at::native::gpu_kernel_impl<at::native::add_kernel_cuda(at::TensorIterator&, c10::Scalar)::{lambda()#1}::operator()() const::{lambda()#4}::operator()() const::{lambda(float, float)#1}>(at::TensorIterator&, at::native::add_kernel_cuda(at::TensorIterator&, c10::Scalar)::{lambda()#1}::operator()() const::{lambda()#4}::operator()() const::{lambda(float, float)#1} const&)::{lambda(int)#2})\n",
      "\n",
      "**ASM:**\n",
      "\n",
      "\t.section\t.text._ZN2at6native18elementwise_kernelILi512ELi1EZNS0_15gpu_kernel_implIZZZNS0_15add_kernel_cudaERNS_14TensorIteratorEN3c106ScalarEENKUlvE_clEvENKUlvE2_clEvEUlffE_EEvS4_RKT_EUliE0_EEviT1_,\"ax\",@progbits\n",
      "\t.sectioninfo\t@\"SHI_REGISTERS=12\"\n",
      "\t.align\t128\n",
      "        .global         _ZN2at6native18elementwise_kernelILi512ELi1EZNS0_15gpu_kernel_implIZZZNS0_15add_kernel_cudaERNS_14TensorIteratorEN3c106ScalarEENKUlvE_clEvENKUlvE2_clEvEUlffE_EEvS4_RKT_EUliE0_EEviT1_\n",
      "        .type           _ZN2at6native18elementwise_kernelILi512ELi1EZNS0_15gpu_kernel_implIZZZNS0_15add_kernel_cudaERNS_14TensorIteratorEN3c106ScalarEENKUlvE_clEvENKUlvE2_clEvEUlffE_EEvS4_RKT_EUliE0_EEviT1_,@function\n",
      "        .size           _ZN2at6native18elementwise_kernelILi512ELi1EZNS0_15gpu_kernel_implIZZZNS0_15add_kernel_cudaERNS_14TensorIteratorEN3c106ScalarEENKUlvE_clEvENKUlvE2_clEvEUlffE_EEvS4_RKT_EUliE0_EEviT1_,(.L_29063 - _ZN2at6native18elementwise_kernelILi512ELi1EZNS0_15gpu_kernel_implIZZZNS0_15add_kernel_cudaERNS_14TensorIteratorEN3c106ScalarEENKUlvE_clEvENKUlvE2_clEvEUlffE_EEvS4_RKT_EUliE0_EEviT1_)\n",
      "        .other          _ZN2at6native18elementwise_kernelILi512ELi1EZNS0_15gpu_kernel_implIZZZNS0_15add_kernel_cudaERNS_14TensorIteratorEN3c106ScalarEENKUlvE_clEvENKUlvE2_clEvEUlffE_EEvS4_RKT_EUliE0_EEviT1_,@\"STO_CUDA_ENTRY STV_DEFAULT\"\n",
      "_ZN2at6native18elementwise_kernelILi512ELi1EZNS0_15gpu_kernel_implIZZZNS0_15add_kernel_cudaERNS_14TensorIteratorEN3c106ScalarEENKUlvE_clEvENKUlvE2_clEvEUlffE_EEvS4_RKT_EUliE0_EEviT1_:\n",
      ".text._ZN2at6native18elementwise_kernelILi512ELi1EZNS0_15gpu_kernel_implIZZZNS0_15add_kernel_cudaERNS_14TensorIteratorEN3c106ScalarEENKUlvE_clEvENKUlvE2_clEvEUlffE_EEvS4_RKT_EUliE0_EEviT1_:\n",
      "\t//## File \"/home/xgao/pytorch2/aten/src/ATen/native/cuda/Loops.cuh\", line 71\n",
      "        /*0000*/                   IMAD.MOV.U32 R1, RZ, RZ, c[0x0][0x28] ;\n",
      "        /*0010*/              @!PT SHFL.IDX PT, RZ, RZ, RZ, RZ ;\n",
      "        /*0020*/                   S2R R0, SR_TID.X ;\n",
      "\t//## File \"/home/xgao/pytorch2/aten/src/ATen/native/cuda/Loops.cuh\", line 73\n",
      "        /*0030*/                   S2R R3, SR_CTAID.X ;\n",
      "        /*0040*/                   IMAD R0, R3, 0x200, R0 ;\n",
      "\t//## File \"/home/xgao/pytorch2/aten/src/ATen/native/cuda/Loops.cuh\", line 76\n",
      "        /*0050*/                   ISETP.GE.AND P0, PT, R0, c[0x0][0x160], PT ;\n",
      "        /*0060*/               @P0 EXIT ;\n",
      "\t//## File \"/home/xgao/pytorch2/aten/src/ATen/native/cuda/Loops.cuh\", line 110\n",
      "        /*0070*/                   IMAD R3, R0.reuse, c[0x0][0x194], RZ ;\n",
      "        /*0080*/                   IMAD R6, R0, c[0x0][0x198], RZ ;\n",
      "        /*0090*/                   IADD3 R4, P0, R3.reuse, c[0x0][0x178], RZ ;\n",
      "        /*00a0*/                   IADD3 R2, P1, R6.reuse, c[0x0][0x180], RZ ;\n",
      "        /*00b0*/                   LEA.HI.X.SX32 R5, R3, c[0x0][0x17c], 0x1, P0 ;\n",
      "        /*00c0*/                   LEA.HI.X.SX32 R3, R6, c[0x0][0x184], 0x1, P1 ;\n",
      "        /*00d0*/                   LDG.E.SYS R5, [R4] ;\n",
      "        /*00e0*/                   LDG.E.SYS R2, [R2] ;\n",
      "\t//## File \"/home/xgao/pytorch2/aten/src/ATen/native/cuda/Loops.cuh\", line 77\n",
      "        /*00f0*/                   IMAD R0, R0, c[0x0][0x190], RZ ;\n",
      "        /*0100*/                   IADD3 R6, P0, R0, c[0x0][0x170], RZ ;\n",
      "        /*0110*/                   LEA.HI.X.SX32 R7, R0, c[0x0][0x174], 0x1, P0 ;\n",
      "\t//## File \"/home/xgao/pytorch2/aten/src/ATen/native/cuda/Loops.cuh\", line 110\n",
      "        /*0120*/                   FFMA R9, R2, c[0x0][0x1a0], R5 ;\n",
      "\t//## File \"/home/xgao/pytorch2/aten/src/ATen/native/cuda/Loops.cuh\", line 170\n",
      "        /*0130*/                   STG.E.SYS [R6], R9 ;\n",
      "\t//## File \"/home/xgao/pytorch2/aten/src/ATen/native/cuda/Loops.cuh\", line 81\n",
      "        /*0140*/                   EXIT ;\n",
      ".L_16826:\n",
      "        /*0150*/                   BRA `(.L_16826);\n",
      "        /*0160*/                   NOP;\n",
      "        /*0170*/                   NOP;\n",
      ".L_29063:\n",
      "\n",
      "**Symbol:**\n",
      "void at::native::elementwise_kernel<512, 1, at::native::gpu_kernel_impl<at::native::gpu_kernel_with_scalars<at::native::add_kernel_cuda(at::TensorIterator&, c10::Scalar)::{lambda()#1}::operator()() const::{lambda()#4}::operator()() const::{lambda(float, float)#1}>(at::TensorIterator&, at::native::add_kernel_cuda(at::TensorIterator&, c10::Scalar)::{lambda()#1}::operator()() const::{lambda()#4}::operator()() const::{lambda(float, float)#1} const&)::{lambda(float)#2}>(at::TensorIterator&, at::native::add_kernel_cuda(at::TensorIterator&, c10::Scalar)::{lambda()#1}::operator()() const::{lambda()#4}::operator()() const::{lambda(float, float)#1})::{lambda(int)#2}>(int, at::native::gpu_kernel_impl<at::native::gpu_kernel_with_scalars<at::native::add_kernel_cuda(at::TensorIterator&, c10::Scalar)::{lambda()#1}::operator()() const::{lambda()#4}::operator()() const::{lambda(float, float)#1}>(at::TensorIterator&, at::native::add_kernel_cuda(at::TensorIterator&, c10::Scalar)::{lambda()#1}::operator()() const::{lambda()#4}::operator()() const::{lambda(float, float)#1} const&)::{lambda(float)#2}>(at::TensorIterator&, at::native::add_kernel_cuda(at::TensorIterator&, c10::Scalar)::{lambda()#1}::operator()() const::{lambda()#4}::operator()() const::{lambda(float, float)#1})::{lambda(int)#2})\n",
      "\n",
      "**ASM:**\n",
      "\n",
      "\t.section\t.text._ZN2at6native18elementwise_kernelILi512ELi1EZNS0_15gpu_kernel_implIZNS0_23gpu_kernel_with_scalarsIZZZNS0_15add_kernel_cudaERNS_14TensorIteratorEN3c106ScalarEENKUlvE_clEvENKUlvE2_clEvEUlffE_EEvS5_RKT_EUlfE0_EEvS5_SD_EUliE0_EEviT1_,\"ax\",@progbits\n",
      "\t.sectioninfo\t@\"SHI_REGISTERS=10\"\n",
      "\t.align\t128\n",
      "        .global         _ZN2at6native18elementwise_kernelILi512ELi1EZNS0_15gpu_kernel_implIZNS0_23gpu_kernel_with_scalarsIZZZNS0_15add_kernel_cudaERNS_14TensorIteratorEN3c106ScalarEENKUlvE_clEvENKUlvE2_clEvEUlffE_EEvS5_RKT_EUlfE0_EEvS5_SD_EUliE0_EEviT1_\n",
      "        .type           _ZN2at6native18elementwise_kernelILi512ELi1EZNS0_15gpu_kernel_implIZNS0_23gpu_kernel_with_scalarsIZZZNS0_15add_kernel_cudaERNS_14TensorIteratorEN3c106ScalarEENKUlvE_clEvENKUlvE2_clEvEUlffE_EEvS5_RKT_EUlfE0_EEvS5_SD_EUliE0_EEviT1_,@function\n",
      "        .size           _ZN2at6native18elementwise_kernelILi512ELi1EZNS0_15gpu_kernel_implIZNS0_23gpu_kernel_with_scalarsIZZZNS0_15add_kernel_cudaERNS_14TensorIteratorEN3c106ScalarEENKUlvE_clEvENKUlvE2_clEvEUlffE_EEvS5_RKT_EUlfE0_EEvS5_SD_EUliE0_EEviT1_,(.L_29067 - _ZN2at6native18elementwise_kernelILi512ELi1EZNS0_15gpu_kernel_implIZNS0_23gpu_kernel_with_scalarsIZZZNS0_15add_kernel_cudaERNS_14TensorIteratorEN3c106ScalarEENKUlvE_clEvENKUlvE2_clEvEUlffE_EEvS5_RKT_EUlfE0_EEvS5_SD_EUliE0_EEviT1_)\n",
      "        .other          _ZN2at6native18elementwise_kernelILi512ELi1EZNS0_15gpu_kernel_implIZNS0_23gpu_kernel_with_scalarsIZZZNS0_15add_kernel_cudaERNS_14TensorIteratorEN3c106ScalarEENKUlvE_clEvENKUlvE2_clEvEUlffE_EEvS5_RKT_EUlfE0_EEvS5_SD_EUliE0_EEviT1_,@\"STO_CUDA_ENTRY STV_DEFAULT\"\n",
      "_ZN2at6native18elementwise_kernelILi512ELi1EZNS0_15gpu_kernel_implIZNS0_23gpu_kernel_with_scalarsIZZZNS0_15add_kernel_cudaERNS_14TensorIteratorEN3c106ScalarEENKUlvE_clEvENKUlvE2_clEvEUlffE_EEvS5_RKT_EUlfE0_EEvS5_SD_EUliE0_EEviT1_:\n",
      ".text._ZN2at6native18elementwise_kernelILi512ELi1EZNS0_15gpu_kernel_implIZNS0_23gpu_kernel_with_scalarsIZZZNS0_15add_kernel_cudaERNS_14TensorIteratorEN3c106ScalarEENKUlvE_clEvENKUlvE2_clEvEUlffE_EEvS5_RKT_EUlfE0_EEvS5_SD_EUliE0_EEviT1_:\n",
      "\t//## File \"/home/xgao/pytorch2/aten/src/ATen/native/cuda/Loops.cuh\", line 73\n",
      "        /*0000*/                   IMAD.MOV.U32 R1, RZ, RZ, c[0x0][0x28] ;\n",
      "        /*0010*/              @!PT SHFL.IDX PT, RZ, RZ, RZ, RZ ;\n",
      "        /*0020*/                   S2R R0, SR_CTAID.X ;\n",
      "\t//## File \"/home/xgao/pytorch2/aten/src/ATen/native/cuda/Loops.cuh\", line 71\n",
      "        /*0030*/                   S2R R3, SR_TID.X ;\n",
      "\t//## File \"/home/xgao/pytorch2/aten/src/ATen/native/cuda/Loops.cuh\", line 73\n",
      "        /*0040*/                   LEA R0, R0, R3, 0x9 ;\n",
      "\t//## File \"/home/xgao/pytorch2/aten/src/ATen/native/cuda/Loops.cuh\", line 76\n",
      "        /*0050*/                   ISETP.GE.AND P0, PT, R0, c[0x0][0x160], PT ;\n",
      "        /*0060*/               @P0 EXIT ;\n",
      "\t//## File \"/home/xgao/pytorch2/aten/src/ATen/native/cuda/Loops.cuh\", line 110\n",
      "        /*0070*/                   IMAD R3, R0, c[0x0][0x184], RZ ;\n",
      "        /*0080*/                   IADD3 R2, P0, R3, c[0x0][0x178], RZ ;\n",
      "        /*0090*/                   LEA.HI.X.SX32 R3, R3, c[0x0][0x17c], 0x1, P0 ;\n",
      "        /*00a0*/                   LDG.E.SYS R2, [R2] ;\n",
      "\t//## File \"/home/xgao/pytorch2/aten/src/ATen/native/cuda/Loops.cuh\", line 77\n",
      "        /*00b0*/                   IMAD R0, R0, c[0x0][0x180], RZ ;\n",
      "\t//## File \"/home/xgao/pytorch2/aten/src/ATen/native/cuda/Loops.cuh\", line 110\n",
      "        /*00c0*/                   IMAD.MOV.U32 R7, RZ, RZ, c[0x0][0x190] ;\n",
      "\t//## File \"/home/xgao/pytorch2/aten/src/ATen/native/cuda/Loops.cuh\", line 77\n",
      "        /*00d0*/                   IADD3 R4, P0, R0, c[0x0][0x170], RZ ;\n",
      "        /*00e0*/                   LEA.HI.X.SX32 R5, R0, c[0x0][0x174], 0x1, P0 ;\n",
      "\t//## File \"/home/xgao/pytorch2/aten/src/ATen/native/cuda/Loops.cuh\", line 110\n",
      "        /*00f0*/                   FFMA R7, R7, c[0x0][0x1a0], R2 ;\n",
      "\t//## File \"/home/xgao/pytorch2/aten/src/ATen/native/cuda/Loops.cuh\", line 170\n",
      "        /*0100*/                   STG.E.SYS [R4], R7 ;\n",
      "\t//## File \"/home/xgao/pytorch2/aten/src/ATen/native/cuda/Loops.cuh\", line 81\n",
      "        /*0110*/                   EXIT ;\n",
      ".L_16980:\n",
      "        /*0120*/                   BRA `(.L_16980);\n",
      "        /*0130*/                   NOP;\n",
      "        /*0140*/                   NOP;\n",
      "        /*0150*/                   NOP;\n",
      "        /*0160*/                   NOP;\n",
      "        /*0170*/                   NOP;\n",
      ".L_29067:\n",
      "\n",
      "**Symbol:**\n",
      "void at::native::elementwise_kernel<512, 1, at::native::gpu_kernel_impl<at::native::gpu_kernel_with_scalars<at::native::add_kernel_cuda(at::TensorIterator&, c10::Scalar)::{lambda()#1}::operator()() const::{lambda()#4}::operator()() const::{lambda(float, float)#1}>(at::TensorIterator&, at::native::add_kernel_cuda(at::TensorIterator&, c10::Scalar)::{lambda()#1}::operator()() const::{lambda()#4}::operator()() const::{lambda(float, float)#1} const&)::{lambda(float)#1}>(at::TensorIterator&, at::native::add_kernel_cuda(at::TensorIterator&, c10::Scalar)::{lambda()#1}::operator()() const::{lambda()#4}::operator()() const::{lambda(float, float)#1})::{lambda(int)#2}>(int, at::native::gpu_kernel_impl<at::native::gpu_kernel_with_scalars<at::native::add_kernel_cuda(at::TensorIterator&, c10::Scalar)::{lambda()#1}::operator()() const::{lambda()#4}::operator()() const::{lambda(float, float)#1}>(at::TensorIterator&, at::native::add_kernel_cuda(at::TensorIterator&, c10::Scalar)::{lambda()#1}::operator()() const::{lambda()#4}::operator()() const::{lambda(float, float)#1} const&)::{lambda(float)#1}>(at::TensorIterator&, at::native::add_kernel_cuda(at::TensorIterator&, c10::Scalar)::{lambda()#1}::operator()() const::{lambda()#4}::operator()() const::{lambda(float, float)#1})::{lambda(int)#2})\n",
      "\n",
      "**ASM:**\n",
      "\n",
      "\t.section\t.text._ZN2at6native18elementwise_kernelILi512ELi1EZNS0_15gpu_kernel_implIZNS0_23gpu_kernel_with_scalarsIZZZNS0_15add_kernel_cudaERNS_14TensorIteratorEN3c106ScalarEENKUlvE_clEvENKUlvE2_clEvEUlffE_EEvS5_RKT_EUlfE_EEvS5_SD_EUliE0_EEviT1_,\"ax\",@progbits\n",
      "\t.sectioninfo\t@\"SHI_REGISTERS=10\"\n",
      "\t.align\t128\n",
      "        .global         _ZN2at6native18elementwise_kernelILi512ELi1EZNS0_15gpu_kernel_implIZNS0_23gpu_kernel_with_scalarsIZZZNS0_15add_kernel_cudaERNS_14TensorIteratorEN3c106ScalarEENKUlvE_clEvENKUlvE2_clEvEUlffE_EEvS5_RKT_EUlfE_EEvS5_SD_EUliE0_EEviT1_\n",
      "        .type           _ZN2at6native18elementwise_kernelILi512ELi1EZNS0_15gpu_kernel_implIZNS0_23gpu_kernel_with_scalarsIZZZNS0_15add_kernel_cudaERNS_14TensorIteratorEN3c106ScalarEENKUlvE_clEvENKUlvE2_clEvEUlffE_EEvS5_RKT_EUlfE_EEvS5_SD_EUliE0_EEviT1_,@function\n",
      "        .size           _ZN2at6native18elementwise_kernelILi512ELi1EZNS0_15gpu_kernel_implIZNS0_23gpu_kernel_with_scalarsIZZZNS0_15add_kernel_cudaERNS_14TensorIteratorEN3c106ScalarEENKUlvE_clEvENKUlvE2_clEvEUlffE_EEvS5_RKT_EUlfE_EEvS5_SD_EUliE0_EEviT1_,(.L_29071 - _ZN2at6native18elementwise_kernelILi512ELi1EZNS0_15gpu_kernel_implIZNS0_23gpu_kernel_with_scalarsIZZZNS0_15add_kernel_cudaERNS_14TensorIteratorEN3c106ScalarEENKUlvE_clEvENKUlvE2_clEvEUlffE_EEvS5_RKT_EUlfE_EEvS5_SD_EUliE0_EEviT1_)\n",
      "        .other          _ZN2at6native18elementwise_kernelILi512ELi1EZNS0_15gpu_kernel_implIZNS0_23gpu_kernel_with_scalarsIZZZNS0_15add_kernel_cudaERNS_14TensorIteratorEN3c106ScalarEENKUlvE_clEvENKUlvE2_clEvEUlffE_EEvS5_RKT_EUlfE_EEvS5_SD_EUliE0_EEviT1_,@\"STO_CUDA_ENTRY STV_DEFAULT\"\n",
      "_ZN2at6native18elementwise_kernelILi512ELi1EZNS0_15gpu_kernel_implIZNS0_23gpu_kernel_with_scalarsIZZZNS0_15add_kernel_cudaERNS_14TensorIteratorEN3c106ScalarEENKUlvE_clEvENKUlvE2_clEvEUlffE_EEvS5_RKT_EUlfE_EEvS5_SD_EUliE0_EEviT1_:\n",
      ".text._ZN2at6native18elementwise_kernelILi512ELi1EZNS0_15gpu_kernel_implIZNS0_23gpu_kernel_with_scalarsIZZZNS0_15add_kernel_cudaERNS_14TensorIteratorEN3c106ScalarEENKUlvE_clEvENKUlvE2_clEvEUlffE_EEvS5_RKT_EUlfE_EEvS5_SD_EUliE0_EEviT1_:\n",
      "\t//## File \"/home/xgao/pytorch2/aten/src/ATen/native/cuda/Loops.cuh\", line 71\n",
      "        /*0000*/                   IMAD.MOV.U32 R1, RZ, RZ, c[0x0][0x28] ;\n",
      "        /*0010*/              @!PT SHFL.IDX PT, RZ, RZ, RZ, RZ ;\n",
      "        /*0020*/                   S2R R0, SR_TID.X ;\n",
      "\t//## File \"/home/xgao/pytorch2/aten/src/ATen/native/cuda/Loops.cuh\", line 73\n",
      "        /*0030*/                   S2R R3, SR_CTAID.X ;\n",
      "        /*0040*/                   LEA R0, R3, R0, 0x9 ;\n",
      "\t//## File \"/home/xgao/pytorch2/aten/src/ATen/native/cuda/Loops.cuh\", line 76\n",
      "        /*0050*/                   ISETP.GE.AND P0, PT, R0, c[0x0][0x160], PT ;\n",
      "        /*0060*/               @P0 EXIT ;\n",
      "\t//## File \"/home/xgao/pytorch2/aten/src/ATen/native/cuda/Loops.cuh\", line 110\n",
      "        /*0070*/                   IMAD R3, R0, c[0x0][0x184], RZ ;\n",
      "        /*0080*/                   IADD3 R2, P0, R3, c[0x0][0x178], RZ ;\n",
      "        /*0090*/                   LEA.HI.X.SX32 R3, R3, c[0x0][0x17c], 0x1, P0 ;\n",
      "        /*00a0*/                   LDG.E.SYS R2, [R2] ;\n",
      "\t//## File \"/home/xgao/pytorch2/aten/src/ATen/native/cuda/Loops.cuh\", line 77\n",
      "        /*00b0*/                   IMAD R0, R0, c[0x0][0x180], RZ ;\n",
      "\t//## File \"/home/xgao/pytorch2/aten/src/ATen/native/cuda/Loops.cuh\", line 110\n",
      "        /*00c0*/                   IMAD.MOV.U32 R7, RZ, RZ, c[0x0][0x190] ;\n",
      "\t//## File \"/home/xgao/pytorch2/aten/src/ATen/native/cuda/Loops.cuh\", line 77\n",
      "        /*00d0*/                   IADD3 R4, P0, R0, c[0x0][0x170], RZ ;\n",
      "        /*00e0*/                   LEA.HI.X.SX32 R5, R0, c[0x0][0x174], 0x1, P0 ;\n",
      "\t//## File \"/home/xgao/pytorch2/aten/src/ATen/native/cuda/Loops.cuh\", line 110\n",
      "        /*00f0*/                   FFMA R7, R2, R7, c[0x0][0x1a0] ;\n",
      "\t//## File \"/home/xgao/pytorch2/aten/src/ATen/native/cuda/Loops.cuh\", line 170\n",
      "        /*0100*/                   STG.E.SYS [R4], R7 ;\n",
      "\t//## File \"/home/xgao/pytorch2/aten/src/ATen/native/cuda/Loops.cuh\", line 81\n",
      "        /*0110*/                   EXIT ;\n",
      ".L_17122:\n",
      "        /*0120*/                   BRA `(.L_17122);\n",
      "        /*0130*/                   NOP;\n",
      "        /*0140*/                   NOP;\n",
      "        /*0150*/                   NOP;\n",
      "        /*0160*/                   NOP;\n",
      "        /*0170*/                   NOP;\n",
      ".L_29071:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import disasm\n",
    "\n",
    "def filter_(demangled_symbol, code):\n",
    "    ret = True\n",
    "    ret &= 'add_kernel' in demangled_symbol             # add kernel\n",
    "    ret &= 'lambda(float, float)' in demangled_symbol   # dtype = float\n",
    "    ret &= 'TypeCast.h' not in code                     # no dynamic casting\n",
    "    ret &= 'OffsetCalculator.cuh' not in code           # trivial 1d\n",
    "    return ret\n",
    "\n",
    "disasm.run('BinaryArithmeticKernel.sm_70.cubin', filter_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
